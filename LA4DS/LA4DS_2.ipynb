{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109b05e3",
   "metadata": {},
   "source": [
    "# Linear Algebra for Data Science. Final Test\n",
    "## Prepared by Said Magomedov, group MFE221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ba382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  .rendered_html {\n",
       "    font-family: \"Palatino\", serif;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  .rendered_html {\n",
    "    font-family: \"Palatino\", serif;\n",
    "  }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac194ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from scipy.linalg import expm\n",
    "from sympy import Matrix\n",
    "from numpy.testing import assert_almost_equal\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d64f4",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "In order to find the best approximation matrix of rank r for given matrix I need to construct the SVD and take rxr leading principal submatrices instead. <br>\n",
    "Finally the L2 norm of a bias matrix by definition must be equal to its largest singular value, i.e. $\\sigma_{r+1}$, where $\\sigma_i$ is a singular value of the Gram matrix of the given one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63716539",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-18,-22,-80,-32],[63,4,2,-34],[-54,-20,56,-4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320159d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall my function from the MidtermTest and modify it for the case of rank 2 \n",
    "def svd2(A):\n",
    "    eigvals, eigvecs = LA.eig(A.T@A)\n",
    "    eigvals = np.where(eigvals < 0, 0, eigvals)\n",
    "    sort_i = np.argsort(eigvals)[::-1]\n",
    "    S = np.diag(np.sqrt(eigvals[sort_i]))\n",
    "    V = eigvecs[:, sort_i]\n",
    "    u0 = A@V[:, 0] / S[0,0]\n",
    "    u1 = A@V[:, 1] / S[1,1]\n",
    "    u2 = A@V[:, 2] / S[2,2]\n",
    "    u3 = np.zeros(3)\n",
    "    U = np.array([u0, u1, u2, u3]).T\n",
    "    \n",
    "    U2 = U[:,:2]\n",
    "    S2 = S[:2,:2]\n",
    "    V2 = V[:,:2]\n",
    "    \n",
    "    SVD2 = U2@S2@V2.T\n",
    "\n",
    "    return [SVD2, U2, S2, V2.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f0b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle A_1 = \\begin{pmatrix}\n",
       "0.667 & 0.667\\\\\n",
       "0.333 & -0.667\\\\\n",
       "-0.667 & 0.333\n",
       "\\end{pmatrix} * \\begin{pmatrix}\n",
       "105.0 & 0.0\\\\\n",
       "0.0 & 84.0\n",
       "\\end{pmatrix} * \\begin{pmatrix}\n",
       "0.429 & -0.0 & -0.857 & -0.286\\\\\n",
       "-0.857 & -0.286 & -0.429 & 0.0\n",
       "\\end{pmatrix} = \\begin{pmatrix}\n",
       "-18.0 & -16.0 & -84.0 & -20.0\\\\\n",
       "63.0 & 16.0 & -6.0 & -10.0\\\\\n",
       "-54.0 & -8.0 & 48.0 & 20.0\n",
       "\\end{pmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrices = svd2(A)\n",
    "output = []\n",
    "for matrix in matrices:\n",
    "    matrix_str = \"\\\\begin{pmatrix}\\n\"\n",
    "    matrix_str += \"\\\\\\\\\\n\".join([\" & \".join(map(str, row)) for row in np.round(matrix, 3)])\n",
    "    matrix_str += \"\\n\\\\end{pmatrix}\"\n",
    "    output.append(matrix_str)\n",
    "    \n",
    "display(Math(fr'A_1 = {output[1]} * {output[2]} * {output[3]} = {output[0]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95b66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = svd2(A)[0]\n",
    "bias_norm = LA.norm(A-A1, ord=2)\n",
    "sigma3 = np.sqrt(np.sort(LA.eigvals(A.T@A))[::-1][2])\n",
    "\n",
    "assert_almost_equal(bias_norm, sigma3, decimal=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f75f6",
   "metadata": {},
   "source": [
    "No assertion error raised, so everything was done correctly and $||A - A_1||_2 = 42$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc722a6c",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3a628",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Consider system $Ax = b$ and its aproximate analogue $\\hat{A}\\hat{x} = \\hat{b}$ such that:\n",
    "$$\\Delta A = \\hat{A} - A \\approx 0, \\quad \\Delta b = \\hat{b} - b \\approx 0, \\quad \\Delta x = \\hat{x} - x \\approx 0$$\n",
    "\n",
    "Relative errors are:\n",
    "$$\\delta A = \\frac{||\\Delta A||}{|A|}, \\quad \\delta b = \\frac{||\\Delta b||}{|b|}, \\quad \\delta x = \\frac{||\\Delta x||}{|x|}$$\n",
    "\n",
    "General formula for the upper bound of the solution relative error:\n",
    "$$\\delta x \\le \\frac{\\kappa(A)}{1-\\kappa(A)\\delta A}(\\delta A + \\delta b),$$ <br>\n",
    "\n",
    "<center> where $\\kappa(A) = ||A|| \\cdot ||A^{-1}||$ is a conditional number of a matrix A <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0214f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-3.92,-0.13],[5.03,-5.84]])\n",
    "b = np.array([-3.99,-0.98])\n",
    "x = LA.inv(A)@b\n",
    "\n",
    "A_hat = np.round(A)\n",
    "b_hat = np.round(b)\n",
    "x_hat = np.round(LA.inv(A_hat)@b_hat) \n",
    "# need to round x_hat here since common Python floating number error raises and returns non-integer values\n",
    "\n",
    "delta_A = A_hat - A\n",
    "delta_b = b_hat - b\n",
    "delta_x = x_hat - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3443a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate solution: (1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(f'Approximate solution: ({x_hat[0]}, {x_hat[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc708a",
   "metadata": {},
   "source": [
    "For the L1 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d585a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the relative error of x in the L1 norm is 0.183.\n"
     ]
    }
   ],
   "source": [
    "kappa_A1 = LA.norm(A, 1) * LA.norm(LA.inv(A), 1) \n",
    "# kappa_A1 = np.linalg.cond(A, 1)\n",
    "\n",
    "re_A1 = LA.norm(delta_A, 1) / LA.norm(A, 1)\n",
    "re_b1 = LA.norm(delta_b, 1) / LA.norm(b, 1)\n",
    "\n",
    "re_x1_ub = (re_A1 + re_b1) * kappa_A1 / (1 - kappa_A1 * re_A1)\n",
    "\n",
    "print(f'The upper bound of the relative error of x in the L1 norm is {re_x1_ub.round(3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d079b8f",
   "metadata": {},
   "source": [
    "For the L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db47cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the relative error of x in the L2 norm is 0.094.\n"
     ]
    }
   ],
   "source": [
    "kappa_A2 = LA.norm(A,ord=2) * LA.norm(LA.inv(A), 2)\n",
    "# kappa_A2 = np.linalg.cond(A, 2)\n",
    "\n",
    "re_A2 = LA.norm(delta_A, 2)/ LA.norm(A, 2)\n",
    "re_b2 = LA.norm(delta_b, 2) / LA.norm(b, 2)\n",
    "\n",
    "re_x2_ub = (re_A2 + re_b2) * kappa_A2 / (1 - kappa_A2 * re_A2)\n",
    "\n",
    "\n",
    "print(f'The upper bound of the relative error of x in the L2 norm is {re_x2_ub.round(3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fdea27",
   "metadata": {},
   "source": [
    "Using the L2 norm lowers the upper bound of relative error of x almost twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fc478f",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c20b347",
   "metadata": {},
   "source": [
    "## Problem 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f89041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate solution: x = -0.9375, y = -1.1875\n"
     ]
    }
   ],
   "source": [
    "A_hat = np.array([[16,-16],[-3,-1]])\n",
    "b_hat = np.array([4,4])\n",
    "x_hat = LA.inv(A_hat)@b_hat\n",
    "\n",
    "print(f'Approximate solution: x = {x_hat[0]}, y = {x_hat[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278840af",
   "metadata": {},
   "source": [
    "For the L2 norm:\n",
    "$$\\Delta b = \\begin{pmatrix} \\varepsilon_3 \\\\ \\varepsilon_4 \\end{pmatrix} \\Rightarrow |\\Delta b|_2 = \\sqrt{\\varepsilon_3^2 + \\varepsilon_4^2} \\le 0.05\\sqrt{2}$$\n",
    "$$\\Downarrow$$\n",
    "$$\\delta b = \\dfrac{|\\Delta b|_2}{|b|_2} \\le \\dfrac{0.05\\sqrt{2}}{4\\sqrt{2}} = 0.0125$$\n",
    "\n",
    "$$\\Delta A = \\begin{pmatrix} -4\\varepsilon_1 & 4\\varepsilon_2 \\\\ 0 & \\varepsilon_1 \\end{pmatrix} \\Rightarrow ||\\Delta A||_2 = \\sigma_{max}(\\Delta A^T\\Delta A) = \\sqrt{\\frac{17\\varepsilon_1^2 + \\varepsilon_2^2 + \\sqrt{(15\\varepsilon_1^2 + \\varepsilon_2^2)^2 + 4\\varepsilon_1^2\\varepsilon_2^2}}{2}} \\le 0.207 \\,(\\text{lower bound is 0)}$$\n",
    "$$\\Downarrow$$\n",
    "$$\\delta A = \\dfrac{||\\Delta A||_2}{||A||_2} \\le \\dfrac{0.207}{8.283} = 0.025 \\,(\\text{lower bound is again 0)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573fcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_A_hat_L2 = LA.norm(A_hat, 2) * LA.norm(LA.inv(A_hat), 2)\n",
    "# kappa_A_hat_2 = LA.cond(A_hat,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c61f5",
   "metadata": {},
   "source": [
    "$$\\delta x \\le \\dfrac{\\kappa(A)}{1-\\kappa(A)\\delta A}(\\delta A + \\delta b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c117cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the relative error of x in the L2 norm is 0.301.\n"
     ]
    }
   ],
   "source": [
    "re_x_L2 = kappa_A_hat_L2 * (0.0125 + 0.025) / (1 - kappa_A_hat_L2 * 0)\n",
    "print(f'The upper bound of the relative error of x in the L2 norm is {re_x_L2.round(3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1b500",
   "metadata": {},
   "source": [
    "For the max norm:\n",
    "$$\\Delta b = \\begin{pmatrix} \\varepsilon_3 \\\\ \\varepsilon_4 \\end{pmatrix} \\Rightarrow |\\Delta b|_\\infty \\le 0.05$$\n",
    "$$\\Downarrow$$\n",
    "$$\\delta b = \\dfrac{|\\Delta b|_\\infty}{|b|_\\infty} \\le \\dfrac{0.05}{4} = 0.0125$$\n",
    "\n",
    "$$\\Delta A = \\begin{pmatrix} -4\\varepsilon_1 & 4\\varepsilon_2 \\\\ 0 & \\varepsilon_1 \\end{pmatrix} \\Rightarrow ||\\Delta A||_\\infty = max\\{4\\varepsilon_1, 4\\varepsilon_2 + \\varepsilon_1\\} \\le 5\\cdot0.05 = 0.25$$\n",
    "$$\\Downarrow$$\n",
    "$$\\delta A = \\dfrac{||\\Delta A||_\\infty}{||A||_\\infty} \\le \\dfrac{0.25}{19} = 0.013$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff3cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound of the relative error of x in the max norm is 0.242.\n"
     ]
    }
   ],
   "source": [
    "kappa_A_hat_Lmax = LA.norm(A_hat, np.inf) * LA.norm(LA.inv(A_hat), np.inf)\n",
    "# kappa_A_hat_2 = LA.cond(A_hat,2)\n",
    "\n",
    "re_x_Lmax = kappa_A_hat_Lmax * (0.0125 + 0.013) / (1 - kappa_A_hat_Lmax * 0)\n",
    "print(f'The upper bound of the relative error of x in the max norm is {re_x_Lmax.round(3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958e8ec",
   "metadata": {},
   "source": [
    "The relative error of the solution is less when performing calculations in the max norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322da5a",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b792672",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "$$\\delta A^{-1} \\le \\frac{\\kappa(A)}{1-\\kappa(A)\\delta A}\\delta A, \\quad \\text{in the L1 norm}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688bfd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation error wrt the L1 norm: 0.004\n"
     ]
    }
   ],
   "source": [
    "A_hat = np.array([[9,-4],[-4,9]])\n",
    "A_hat_inv = LA.inv(A_hat)\n",
    "delta_A = 0.01 * np.ones((2,2))\n",
    "re_A = LA.norm(delta_A, 1) / LA.norm(A_hat, 1)\n",
    "\n",
    "kappa_A = LA.norm(A_hat, 1) * LA.norm(A_hat_inv, 1)\n",
    "re_Ainv = kappa_A * re_A / (1 - kappa_A * re_A)\n",
    "\n",
    "print(f'Approximation error wrt the L1 norm: {re_Ainv.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10ae06",
   "metadata": {},
   "source": [
    "$$A^{-1} \\approx \\dfrac{1}{65} \\cdot \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix} = \\begin{pmatrix} 0.138 & 0.062 \\\\ 0.062 & 0.138 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95725753",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83476756",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "Rewrite initial system in the following way:\n",
    "$$Ax = B \\Longleftrightarrow x_{k+1} = Px_k + b$$\n",
    "Then if $x^*$ is the true solution, find an approximate one by iterating through the second system till $|x_k-x^*| \\le \\dfrac{|x_{k+1} - x_k|}{1-||P||} \\le 0.01$. <br>\n",
    "The starting point is a zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4293cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[22,1,6],[7,20,2],[1,2,21]])\n",
    "B = np.array([9,1,2])\n",
    "x_star = LA.inv(A)@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4daf530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[0,-1/22,-6/22],[-7/20,0,-2/20],[-1/21,-2/21,0]])\n",
    "b = np.array([9/22,1/20,2/21])\n",
    "\n",
    "P_norm = LA.norm(P, np.inf)\n",
    "print(P_norm <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "634075dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 4\n",
      "Approximate solution: x = 0.39, y = -0.097, z = 0.085\n",
      "Approximation error: 0.002\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "x_old = np.zeros(3)\n",
    "x_new = P@x_old + b\n",
    "error = LA.norm(x_new - x_old, ord=np.inf) / (1 - P_norm)\n",
    "\n",
    "while error > 0.01:\n",
    "    x_old = x_new\n",
    "    x_new = P@x_old + b\n",
    "    error = LA.norm(x_new - x_old, ord=np.inf) / (1 - P_norm)\n",
    "    step += 1\n",
    "\n",
    "sol = x_old.round(3)\n",
    "eps = LA.norm(x_old - x_star, np.inf).round(3)\n",
    "print(f'Iterations: {step}', \n",
    "      f'Approximate solution: x = {sol[0]}, y = {sol[1]}, z = {sol[2]}', \n",
    "      f'Approximation error: {eps}', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f4f1f",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3297f",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "Given a graph adjacency matrix A construct the probability matrix P and also the matrix Q of equal probabilities (ones over dimension), $\\alpha$ is a dumping factor <br>\n",
    "$$\\tilde{P} = \\alpha \\cdot P + (1-\\alpha) \\cdot Q$$\n",
    "\n",
    "Then iterate over a range of powers k in order to obtain some convergent solution:\n",
    "$$X_{k+1} = \\tilde{P} \\cdot X_k$$\n",
    "\n",
    "The most influential vertex will correspond to the index of the greatest value of the found PageRank vector X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1acc0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03       0.31333333 0.03       0.03       0.455     ]\n",
      " [0.03       0.03       0.2425     0.03       0.03      ]\n",
      " [0.03       0.31333333 0.2425     0.03       0.03      ]\n",
      " [0.03       0.03       0.2425     0.455      0.455     ]\n",
      " [0.88       0.31333333 0.2425     0.455      0.03      ]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.85\n",
    "A = np.array([[0,0,0,0,1],[1,0,1,0,1],[0,1,1,1,1],[0,0,0,1,1],[1,0,0,1,0]]).T\n",
    "P = A / A.sum(axis=0)\n",
    "Q = np.ones((5,5)) / 5\n",
    "Ptilde = alpha * P + (1 - alpha) * Q\n",
    "print(Ptilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee49b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank vector: [0.19729979 0.04124893 0.05293612 0.34236787 0.36614729]\n",
      "The most influential vertex: 5\n"
     ]
    }
   ],
   "source": [
    "X0 = np.array([[1/5],[1/5],[1/5],[1/5],[1/5]])\n",
    "X = X0\n",
    "for i in range(1000):\n",
    "    X = Ptilde.dot(X)\n",
    "    \n",
    "print(f'PageRank vector: {np.ravel(X)}', \n",
    "      f'The most influential vertex: {np.argmax(X) + 1}', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a08af6",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa6261",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "$$f(A) = e^{A+2\\cdot I} = \\sum \\limits_{k=0}^{\\infty} \\frac{(A+2\\cdot I)^k}{k!} = \\left[\\text{apply diagonalization:}\\, A+2\\cdot I = VDV^{-1} \\right] = I + \\frac{VDV^{-1}}{1!} + \\frac{VDV^{-1}VDV^{-1}}{2!} + \\frac{VDV^{-1}VDV^{-1}VDV^{-1}}{3!} + \\dots = I + \\frac{VDV^{-1}}{1!} + \\frac{VD^2V^{-1}}{2!} + \\frac{VD^3V^{-1}}{3!} + \\dots = V \\left(\\sum \\limits_{k=0}^{\\infty} \\frac{D^k}{k!}\\right)V^{-1} = V\\begin{pmatrix} \\sum \\limits_{k=0}^{\\infty} \\frac{\\lambda_1^k}{k!} & 0 & 0 \\\\ 0 & \\sum \\limits_{k=0}^{\\infty} \\frac{\\lambda_2^k}{k!} & 0 \\\\ 0 & 0 & \\sum \\limits_{k=0}^{\\infty} \\frac{\\lambda_3^k}{k!} \\end{pmatrix} V^{-1} = V \\begin{pmatrix} e^{\\lambda_1} & 0 & 0 \\\\ 0 & e^{\\lambda_2} & 0 \\\\ 0 & 0 & e^{\\lambda_3} \\end{pmatrix} V^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59e2dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[20,-5,6],[59,-15,21],[-5,1,1]])\n",
    "A_plus_2 = A + 2*np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ac38ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# make sure that the obtained matrix is diagonalizable\n",
    "print(Matrix(A_plus_2).is_diagonalizable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "886f2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_matrix(A):\n",
    "    lam, V = LA.eig(A)\n",
    "    exp_lam = np.exp(lam)\n",
    "    exp_D = np.diag(exp_lam)\n",
    "    \n",
    "    return V@exp_D@LA.inv(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39fc573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle f(A) = \\begin{pmatrix}\n",
       "1694.057 & -423.514 & 443.6\\\\\n",
       "3769.74 & -947.456 & 1067.97\\\\\n",
       "-1392.774 & 343.172 & -303.001\n",
       "\\end{pmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "funcA = exp_matrix(A_plus_2)\n",
    "matrix_str = \"\\\\begin{pmatrix}\\n\"\n",
    "matrix_str += \"\\\\\\\\\\n\".join([\" & \".join(map(str, row)) for row in np.round(funcA, 3)])\n",
    "matrix_str += \"\\n\\\\end{pmatrix}\"\n",
    "display(Math(fr'f(A) = {matrix_str}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66966fa",
   "metadata": {},
   "source": [
    "Let's check the result using the built-in `scipy` function `expm()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "756d56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(funcA, expm(A_plus_2), decimal=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
