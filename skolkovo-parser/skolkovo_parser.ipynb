{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e873f71",
   "metadata": {},
   "source": [
    "# The task is to scrap certain information for about 500 companies (with some filters) from the Skolkovo website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc276a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e5fca",
   "metadata": {},
   "source": [
    "### Parse websites with information on all companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a74d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "myUrl = \"https://navigator.sk.ru/?q=N4IgZiBcoC4IYHMDOB9GBPADgUyiA9gE4gA0IAloQDZShiH4C2epIM%2BLAvmY9beA2aQQrdlzIw%2B0AUxYSOwkNxBIArgCNG5GAGF8qgHYwoARjIBjJpjgH0KQtgBu2A6tzT6syACYADP-95cRBzKTpBOTYFEU5lJDwAWkZsRnVsQhQkcgNzXDJMU04gA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c33ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(myUrl)\n",
    "\n",
    "# define a function that simulates pressing the \"More\" button\n",
    "\n",
    "def click_load_more_button():\n",
    "    while True:\n",
    "        try:\n",
    "            button = driver.find_element(By.CLASS_NAME, \"load-more__button\")\n",
    "            button.click()\n",
    "            time.sleep(40) # so that the page has time to load\n",
    "        except:\n",
    "            break\n",
    "\n",
    "\n",
    "loading_start = time.time()\n",
    "click_load_more_button()\n",
    "\n",
    "company_hrefs = []\n",
    "\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "companies_div = soup.find_all(\"a\", class_=\"card company-card card_navigator w-inline-block\")\n",
    "for company in tqdm(companies_div):\n",
    "    company_hrefs.append(company[\"href\"])\n",
    "\n",
    "loading_time = time.time() - loading_start # just for fun, let's see how long the whole procedure takes\n",
    "\n",
    "len(company_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://navigator.sk.ru{}\"\n",
    "\n",
    "company_urls = []\n",
    "for company in tqdm(company_hrefs):\n",
    "    final_url = base_url.format(company)\n",
    "    company_urls.append(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e15ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each company's website so as not to repeat the procedure every time\n",
    "with open(\"skolkovo_parce/skolkovo_urls.pkl\", \"wb\") as file:\n",
    "    pickle.dump(company_urls, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3369c90",
   "metadata": {},
   "source": [
    "### Parse the data of interest for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the latter file\n",
    "with open(\"skolkovo_parce/skolkovo_urls.pkl\", \"rb\") as file:\n",
    "    skolkovo_urls = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info = []\n",
    "\n",
    "for company in tqdm(range(432, len(skolkovo_urls))):\n",
    "    d = {}\n",
    "    url = skolkovo_urls[company]\n",
    "    webpage = requests.get(url).text\n",
    "    soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "    d[\"Название\"] = soup.find(\"p\", class_=\"page__subtitle\").text\n",
    "    \n",
    "    website = soup.find(\"a\", class_=\"sidebar-item web-alpha-icon\")\n",
    "    if website:\n",
    "        d[\"Сайт\"] = website[\"href\"]\n",
    "    else:\n",
    "        d[\"Сайт\"] = \"Сайт отсутствует\"\n",
    "        \n",
    "    description = soup.find(\"div\", class_=\"page-section__main-text\")\n",
    "    if description:\n",
    "        d[\"Описание\"] = description.text\n",
    "    else:\n",
    "        d[\"Описание\"] = \"Описание отсутствует\"\n",
    "    \n",
    "    thead = soup.find(\"thead\")\n",
    "    thead_rows = thead.find_all(\"th\")\n",
    "    inv_thead = [cell.text for cell in thead_rows]\n",
    "    tbody = soup.find(\"tbody\")\n",
    "    tbody_rows = tbody.find_all(\"tr\")[:2]\n",
    "    inv_tbody = []\n",
    "    for row in tbody_rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        num_cells = []\n",
    "        for i in range(1, len(cells)):\n",
    "            num = int(cells[i].find(\"span\", class_=\"number\").text.replace(\" \", \"\").replace(\"₽\", \"\"))\n",
    "            num_cells.append(num)\n",
    "         \n",
    "        inv_tbody.append([cells[0].text] + num_cells)\n",
    "    d[\"Инвестиции\"] = [inv_thead, inv_tbody]\n",
    "    \n",
    "    d[\"ОГРН\"] = int(soup.find(\"div\", text=\"ОГРН\").find_parent(\"div\").find(\"a\").text)\n",
    "    \n",
    "    founders = soup.find_all(\"div\", class_=\"contact-item__text-2 contact-item__row uppercase\")\n",
    "    formatted_founders = []\n",
    "    for founder in founders:\n",
    "        p_elements = founder.find_all(\"p\")\n",
    "        fio = p_elements[0].text\n",
    "        percent = p_elements[1].text\n",
    "        formatted_founders.append(f\"{fio} ({percent})\")\n",
    "    d[\"Учредители\"] = \", \".join(formatted_founders)\n",
    "    \n",
    "    company_info.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list with information on all companies\n",
    "with open(\"skolkovo_parce/final_list.pkl\", \"wb\") as file:\n",
    "    pickle.dump(company_info, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2155191",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112477fb",
   "metadata": {},
   "source": [
    "### Work with a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the latter file\n",
    "with open(\"final_list.pkl\", \"rb\") as file:\n",
    "    final_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_list)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb187040",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df[\"Инвестиции\"])):\n",
    "    diff = len(df[\"Инвестиции\"][i][1][0]) - 4\n",
    "    if diff < 0:\n",
    "        df[\"Инвестиции\"][i][1][0] += [\"--\"] * abs(diff)\n",
    "        df[\"Инвестиции\"][i][1][1] += [\"--\"] * abs(diff)\n",
    "    else:\n",
    "        pass\n",
    "    df.loc[i, [\"Rev 2022\", \"Rev 2021\", \"Rev 2020\"]] = df[\"Инвестиции\"][i][1][0][1:]\n",
    "    df.loc[i, [\"NI 2022\", \"NI 2021\", \"NI 2020\"]] = df[\"Инвестиции\"][i][1][1][1:]\n",
    "del df[\"Инвестиции\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df453a",
   "metadata": {},
   "source": [
    "#### Save as Excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00141755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"scrapTable_Lena.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
